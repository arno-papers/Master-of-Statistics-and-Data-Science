{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qJy5XoByTKn"
      },
      "source": [
        "# Exercises on Spark SQL/DataFrame API\n",
        "<font color='violet'>Any changes made to the notebook text for the homework assignment are indicated in violet.</font>\n",
        "\n",
        "This notebook contains the spark exercises using the **Spark SQL/DataFrame API**.\n",
        "\n",
        "We start by installing pyspark (only execute if this is needed, e.g., if you are running this on Google Colab), and downloading the datasets. The exercises, which are the same as for the CORE API, follow.\n",
        "\n",
        "### Useful documentation to do these exercises.\n",
        "\n",
        "The PySpark Documentation is available at https://spark.apache.org/docs/latest/api/python/index.html. \n",
        "\n",
        "Instructions on how to install PySpark on your local PC may be found at https://spark.apache.org/docs/latest/api/python/getting_started/install.html. Note that by installing PySpark in this way, you automatically have a local copy of Spark.\n",
        "\n",
        "The Spark SQL and Dataframe API api that we use below has the following  documentation which is a useful reference to have: https://spark.apache.org/docs/latest/sql-programming-guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPDnAZE9us6F"
      },
      "source": [
        "#### Installing PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z5Xe86sus6F",
        "outputId": "313af8e2-92f7-4ae1-f93a-54bb0e8bc220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=a3dbac6cd3b19db66a6dd6a9b44958b9d099be4769e02a0629e520d5c62b4bdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "# This installs pyspark in the current python environment.\n",
        "# By installing pyspark, we automatically also install spark.\n",
        "# You **need** to run this cell when running this notebook in google colab\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvPogFL6us6H"
      },
      "source": [
        "#### General imports and starting Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DP9Uj34dus6I"
      },
      "outputs": [],
      "source": [
        "#This is needed to start a Spark session from the notebook\n",
        "#You may adjust the memory used by the driver program based on your machine's settings\n",
        "import os \n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
        "\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "kYOmJ0njus6J",
        "outputId": "703c951a-f6aa-41f6-9e9b-940907cc60e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=demoRDD>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3e2242a5612e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demoRDD</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# Start Spark in LOCAL mode\n",
        "# -------------------------------\n",
        "\n",
        "#The following lines are just there to allow this cell to be re-executed multiple times:\n",
        "#if a spark session was already started, we stop it before starting a new one\n",
        "#(there can be only one spark context per jupyter notebook)\n",
        "try: \n",
        "    spark\n",
        "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
        "    spark.stop()\n",
        "except: \n",
        "    pass\n",
        "\n",
        "# Create a new spark session (note, the * indicates to use all available CPU cores)\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"demoRDD\") \\\n",
        "    .getOrCreate()\n",
        "    \n",
        "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
        "sc=spark.sparkContext\n",
        "\n",
        "# We print the sparkcontext. This prints general information about the spark instance we have connected to. \n",
        "# In particular, the hyperlink allows us to open the spark UI (useful for seeing what is going on)\n",
        "# Note: this hyperlink won't work when running this notebook in Google Colab.\n",
        "sc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55F4k_N-wgmZ"
      },
      "source": [
        "### Downloading data\n",
        "\n",
        "The next cell downloads the data required to do the exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSHIau9kwkD-",
        "outputId": "34520c2a-fbd2-4b32-d444-92e78a295b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 19:36:31--  https://drive.google.com/u/0/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.191.138, 64.233.191.101, 64.233.191.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.191.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download [following]\n",
            "--2023-03-31 19:36:31--  https://drive.google.com/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-50-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/boenlfe2l782e86v8f8fgsiqiici1leh/1680291375000/12785547293638390956/*/1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS?e=download&uuid=f4790f26-2834-4a42-81c7-a7ab12fe7556 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-31 19:36:33--  https://doc-0o-50-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/boenlfe2l782e86v8f8fgsiqiici1leh/1680291375000/12785547293638390956/*/1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS?e=download&uuid=f4790f26-2834-4a42-81c7-a7ab12fe7556\n",
            "Resolving doc-0o-50-docs.googleusercontent.com (doc-0o-50-docs.googleusercontent.com)... 142.250.1.132, 2607:f8b0:4001:c24::84\n",
            "Connecting to doc-0o-50-docs.googleusercontent.com (doc-0o-50-docs.googleusercontent.com)|142.250.1.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15656709 (15M) [application/zip]\n",
            "Saving to: ‘downloads/data-spark-exercises.zip’\n",
            "\n",
            "downloads/data-spar 100%[===================>]  14.93M  95.1MB/s    in 0.2s    \n",
            "\n",
            "2023-03-31 19:36:33 (95.1 MB/s) - ‘downloads/data-spark-exercises.zip’ saved [15656709/15656709]\n",
            "\n",
            "books  github  movielens  sensors\n"
          ]
        }
      ],
      "source": [
        "!mkdir downloads\n",
        "!wget 'https://drive.google.com/u/0/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download' -O downloads/data-spark-exercises.zip\n",
        "!unzip -q downloads/data-spark-exercises.zip\n",
        "!ls data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNlBVQqyTKp"
      },
      "source": [
        "## 1. Sensor data exercises\n",
        "In the file “data/sensors/sensor-sample.txt” you will find on each line, multiple fields of information, let’s call them : Date(Date), Time(Time), RoomId(Integer)-SensorId(Integer), Value1(float), Value2(float)\n",
        "Using this file, use spark to compute the following queries :\n",
        "\n",
        "1. Count the number of entries for each day.\n",
        "2. Count the number of measures for each pair of RoomId-SensorId.\n",
        "3. Compute the average of Value1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RuxgRx46kj"
      },
      "source": [
        "<font color='violet'>Reading in the data:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c0oM3T444aq",
        "outputId": "3313c0db-e98f-4386-e041-0f62894c3f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+--------+-------+\n",
            "|      Date|                Time|RoomIdDashSensorId|  Value1| Value2|\n",
            "+----------+--------------------+------------------+--------+-------+\n",
            "|2017-03-31|2023-03-31 03:38:...|               1-0| 122.153|2.03397|\n",
            "|2017-03-31|2023-03-31 03:38:...|               1-1|-3.91901|2.09397|\n",
            "|2017-03-31|2023-03-31 03:38:...|               1-2|   11.04|2.07397|\n",
            "|2017-02-28|2023-03-31 00:59:...|               1-0| 19.9884|2.74964|\n",
            "|2017-02-28|2023-03-31 00:59:...|               1-1| 37.0933|2.76964|\n",
            "+----------+--------------------+------------------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema1 = \"Date DATE, Time TIMESTAMP, RoomIdDashSensorId STRING, Value1 FLOAT, Value2 FLOAT\"\n",
        "sensorDF = spark.read.option(\"delimiter\", \" \").csv(\"data/sensors/sensor-sample.txt\", schema=schema1)\n",
        "sensorDF.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw-WB7-R4wp6"
      },
      "source": [
        "<font color='violet'>1. Count the number of entries for each day.\n",
        "\n",
        "The sorting is not strictly necessary, but helps verify the correctness of the result, and comparison with notebook 2:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j16jzIkx2D5l",
        "outputId": "8ddbc10a-821f-4017-f44b-4ab67b268e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|      Date|count|\n",
            "+----------+-----+\n",
            "|2017-02-28|62103|\n",
            "|2017-03-01|33423|\n",
            "|2017-03-02|32403|\n",
            "|2017-03-03|29727|\n",
            "|2017-03-04|30225|\n",
            "+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sensorDF.groupBy(\"Date\").count().sort(\"Date\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCsLIFwl7sT1"
      },
      "source": [
        "<font color='violet'>2. Count the number of measures for each pair of RoomId-SensorId.\n",
        "\n",
        "Again, sorting is not stirctly needed:</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHM289ty2HFq",
        "outputId": "dd522c53-4895-411c-85ae-03c9b168b17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|RoomIdDashSensorId|count|\n",
            "+------------------+-----+\n",
            "|               1-0|43047|\n",
            "|               1-1|43047|\n",
            "|               1-2|43047|\n",
            "|               2-0|46915|\n",
            "|               2-1|46915|\n",
            "+------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sensorDF.groupBy(\"RoomIdDashSensorId\").count().sort(\"RoomIdDashSensorId\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrPPS7HG2HZj"
      },
      "source": [
        "<font color='violet'> 3. Compute the average of Value1: </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf7ehgot7v-V",
        "outputId": "8c65e1d1-affe-4ac2-afe1-492ca8d26a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|      avg(Value1)|\n",
            "+-----------------+\n",
            "|92.82106000775526|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import mean\n",
        "sensorDF.select(mean(\"Value1\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDGiJQn7hyQ"
      },
      "source": [
        "<font color='violet'> Or alternatively: </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6w41L3I_4Q4",
        "outputId": "b1e815cf-f356-443e-a29d-d1d4d076a6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|      avg(Value1)|\n",
            "+-----------------+\n",
            "|92.82106000775526|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sensorDF.groupby().mean(\"Value1\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwxpq5_NyTKv"
      },
      "source": [
        "## 2. Movielens movie data exercises\n",
        "\n",
        "Movielens (https://movielens.org/) is a website that provides non-commercial, personalised movie recommendations. GroupLens Research has collected and made available rating data sets from the MovieLens web site for the purpose of research into making recommendation services. In this exercise, we will use one of these datasets (the movielens latest dataset, http://files.grouplens.org/datasets/movielens/ml-latest-small.zip) and compute some basic queries on it.\n",
        "The dataset has already been downloaded and is available at data/movielens/movies.csv, data/movielens/ratings.csv, data/movielens/tags.csv, data/movielens/links.csv\n",
        "\n",
        "1. Inspect the dataset's [README file](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html), in particular the section titled \"Content and Use of Files\" to learn the structure of these three files.\n",
        "2. Compute all pairs (`movieid`, `rat`) where `movieid` is a movie id (as found in ratings.csv) and `rat` is the average rating of that movie id. (Hint: use aggregateByKey to compute first the sum of all ratings as well as the number of ratings per key).\n",
        "3. Compute all pairs (`title`, `rat`) where `title` is a full movie title (as found in the movies.csv file), and `rat` is the average rating of that movie (computed over all possible ratings for that movie, as found in the ratings.csv file)\n",
        "4. [_Extra_] Compute all pairs (`title`, `tag`) where `title` is a full movie title that has an average rating of at least 3.5, and `tag` is a tag for that movie (as found in the tags.csv file)\n",
        "\n",
        "Extra: if you want to experiment with larger datasets, download the 10m dataset (http://files.grouplens.org/datasets/movielens/ml-10m.zip, 250 Mb uncompressed) and re-do the exercises above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNwtRZcS8r8q"
      },
      "source": [
        "<font color='violet'>Reading in the data.\n",
        "\n",
        "\"timestamp\" should be converted to a proper DATE/TIME format instead of INT,\n",
        "but since that column is not used in the exercises, I did not put in the additional effort.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKW79o6m8z-C",
        "outputId": "af9284b1-a743-4938-c78a-6b886461ce0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "|     1|     47|   5.0|964983815|\n",
            "|     1|     50|   5.0|964982931|\n",
            "+------+-------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema2_1 = \"userId INT,movieId INT,rating FLOAT,timestamp INT\"\n",
        "ratingsDF = spark.read.option(\"delimiter\", \",\").csv(\"data/movielens/ratings.csv\", schema=schema2_1)\n",
        "ratingsDF.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMykMgWf-t--",
        "outputId": "3688b4dd-1336-48c1-edf2-0f9dccbea709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema2_2 = \"movieId INT,title STRING,genres STRING\"\n",
        "moviesDF = spark.read.option(\"delimiter\", \",\").csv(\"data/movielens/movies.csv\", schema=schema2_2)\n",
        "moviesDF.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBJdCG4HBgCi",
        "outputId": "1e8400d5-268c-478c-f306-0ddba0d4d5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+---------------+----------+\n",
            "|userId|movieId|            tag| timestamp|\n",
            "+------+-------+---------------+----------+\n",
            "|     2|  60756|          funny|1445714994|\n",
            "|     2|  60756|Highly quotable|1445714996|\n",
            "|     2|  60756|   will ferrell|1445714992|\n",
            "|     2|  89774|   Boxing story|1445715207|\n",
            "|     2|  89774|            MMA|1445715200|\n",
            "+------+-------+---------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema2_3 = \"userId INT, movieId INT, tag STRING, timestamp INT\"\n",
        "tagsDF = spark.read.option(\"delimiter\", \",\").csv(\"data/movielens/tags.csv\", schema=schema2_3)\n",
        "tagsDF.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfgTIaJH9r3S"
      },
      "source": [
        "<font color='violet'> 1. is the same as in notebook 2. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hG1J5y8lfX"
      },
      "source": [
        "<font color='violet'> 2. Compute all pairs (movieid, rat) where movieid is a movie id (as found in ratings.csv) and rat is the average rating of that movie id. (Hint: use aggregateByKey to compute first the sum of all ratings as well as the number of ratings per key).\n",
        "\n",
        "Again, sorting is not strictly needed:\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PCK0sxb-wVZ",
        "outputId": "400dbd5c-b7cf-4d31-c500-a070a4db1d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|movieId|       avg(rating)|\n",
            "+-------+------------------+\n",
            "|      1|3.9209302325581397|\n",
            "|      2|3.4318181818181817|\n",
            "|      3|3.2596153846153846|\n",
            "|      4| 2.357142857142857|\n",
            "|      5|3.0714285714285716|\n",
            "+-------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratingsDF.groupBy(\"movieId\").mean(\"rating\").sort(\"movieId\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTyt4NdAN3_"
      },
      "source": [
        "<font color='violet'>3. Compute all pairs (`title`, `rat`) where `title` is a full movie title (as found in the movies.csv file), and `rat` is the average rating of that movie (computed over all possible ratings for that movie, as found in the ratings.csv file)\n",
        "\n",
        "Again, sorting is not strictly necessary.\n",
        "Also note that, compared to notebook 2, the September 11 movie is sorted to the first position, instead of the 32nd. There are additional quotes present around the title that were not properly stripped:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zovGs2lIBjGn",
        "outputId": "cb387f87-7fcc-4f0e-dc42-dc56841e7a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------+------------------+\n",
            "|title                                                 |avg(rating)       |\n",
            "+------------------------------------------------------+------------------+\n",
            "|\"11'09\"\"01 - September 11 (2002)\"                     |4.0               |\n",
            "|'71 (2014)                                            |4.0               |\n",
            "|'Hellboy': The Seeds of Creation (2004)               |4.0               |\n",
            "|'Round Midnight (1986)                                |3.5               |\n",
            "|'Salem's Lot (2004)                                   |5.0               |\n",
            "|'Til There Was You (1997)                             |4.0               |\n",
            "|'Tis the Season for Love (2015)                       |1.5               |\n",
            "|'burbs, The (1989)                                    |3.176470588235294 |\n",
            "|'night Mother (1986)                                  |3.0               |\n",
            "|(500) Days of Summer (2009)                           |3.6666666666666665|\n",
            "|*batteries not included (1987)                        |3.2857142857142856|\n",
            "|...All the Marbles (1981)                             |2.0               |\n",
            "|...And Justice for All (1979)                         |3.1666666666666665|\n",
            "|00 Schneider - Jagd auf Nihil Baxter (1994)           |4.5               |\n",
            "|1-900 (06) (1994)                                     |4.0               |\n",
            "|10 (1979)                                             |3.375             |\n",
            "|10 Cent Pistol (2015)                                 |1.25              |\n",
            "|10 Cloverfield Lane (2016)                            |3.6785714285714284|\n",
            "|10 Items or Less (2006)                               |2.6666666666666665|\n",
            "|10 Things I Hate About You (1999)                     |3.5277777777777777|\n",
            "|10 Years (2011)                                       |3.5               |\n",
            "|10,000 BC (2008)                                      |2.7058823529411766|\n",
            "|100 Girls (2000)                                      |3.25              |\n",
            "|100 Streets (2016)                                    |2.5               |\n",
            "|101 Dalmatians (1996)                                 |3.074468085106383 |\n",
            "|101 Dalmatians (One Hundred and One Dalmatians) (1961)|3.4318181818181817|\n",
            "|101 Dalmatians II: Patch's London Adventure (2003)    |2.5               |\n",
            "|101 Reykjavik (101 Reykjavík) (2000)                  |3.5               |\n",
            "|102 Dalmatians (2000)                                 |2.7777777777777777|\n",
            "|10th & Wolf (2006)                                    |4.5               |\n",
            "|10th Kingdom, The (2000)                              |2.75              |\n",
            "|10th Victim, The (La decima vittima) (1965)           |4.0               |\n",
            "+------------------------------------------------------+------------------+\n",
            "only showing top 32 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratingsDF.join(moviesDF, ratingsDF.movieId == moviesDF.movieId).groupBy(\"title\").mean(\"rating\").sort(\"title\").show(32,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldatrTtmHC-V"
      },
      "source": [
        "<font color='violet'>Or alternatively:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwueFdDGQJr",
        "outputId": "dc318f6f-2c68-4193-9726-91f2218e20ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------+-----------+\n",
            "|title                                  |avg(rating)|\n",
            "+---------------------------------------+-----------+\n",
            "|\"11'09\"\"01 - September 11 (2002)\"      |4.0        |\n",
            "|'71 (2014)                             |4.0        |\n",
            "|'Hellboy': The Seeds of Creation (2004)|4.0        |\n",
            "|'Round Midnight (1986)                 |3.5        |\n",
            "|'Salem's Lot (2004)                    |5.0        |\n",
            "+---------------------------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratingsDF.groupBy(\"movieId\").mean(\"rating\").join(moviesDF, ratingsDF.movieId == moviesDF.movieId).select(\"title\",\"avg(rating)\").sort(\"title\").show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5-DEInW_dNR"
      },
      "source": [
        "<font color='violet'> 4. [_Extra_] Compute all pairs (title, tag) where title is a full movie title that has an average rating of at least 3.5, and tag is a tag for that movie (as found in the tags.csv file)\n",
        "\n",
        "Again, sorting is not strictly needed, and the average rating is only included to verify the that no ratings less than 3.5 are listed.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqeStExA_UTz",
        "outputId": "3fb29daf-7398-49b3-84f4-e1d6a381376d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+---------------------+-----------+\n",
            "|title                          |tag                  |avg(rating)|\n",
            "+-------------------------------+---------------------+-----------+\n",
            "|Age of Innocence, The (1993)   |Edith Wharton        |3.5        |\n",
            "|Ghost World (2001)             |adolescence          |3.5        |\n",
            "|Othello (1995)                 |Shakespeare          |3.5        |\n",
            "|Crossfire (1947)               |anti-Semitism        |3.5        |\n",
            "|Preacher's Wife, The (1996)    |religion             |3.5        |\n",
            "|Shadow of the Thin Man (1941)  |Nick and Nora Charles|3.5        |\n",
            "|Return of the Secaucus 7 (1980)|In Netflix queue     |3.5        |\n",
            "|Possession (2002)              |books                |3.5        |\n",
            "|My Life (1993)                 |death                |3.5        |\n",
            "|Beat the Devil (1953)          |crime                |3.5        |\n",
            "+-------------------------------+---------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratingsDF.groupBy(\"movieId\")\\\n",
        "         .mean(\"rating\")\\\n",
        "         .filter(\"avg(rating)>=3.5\")\\\n",
        "         .join(tagsDF,ratingsDF.movieId == tagsDF.movieId)\\\n",
        "         .join(moviesDF, ratingsDF.movieId == moviesDF.movieId)\\\n",
        "         .select(\"title\",\"tag\",\"avg(rating)\")\\\n",
        "         .sort(\"avg(rating)\")\\\n",
        "         .show(10,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHDM49PyTKx"
      },
      "source": [
        "## 3. Github log data exercises\n",
        "Github makes activity logs publicly available at https://www.githubarchive.org/. One such log file, which contains activity data for 2015-03-01 between 0h-1h at night, has been downloaded and is available at `data/github/2015-03-01-0.json.gz`. This (compressed) file contains multiple JSON objects, one per line. Here is a sample line of this file, neatly formatted:\n",
        "\n",
        "`{ \"id\": \"2614896652\",\n",
        "    \"type\": \"CreateEvent\",\n",
        "    \"actor\": {\n",
        "        \"id\": 739622,\n",
        "        \"login\": \"treydock\",\n",
        "        \"gravatar_id\": \"\",\n",
        "        \"url\": \"https://api.githb.com/users/treydock\",\n",
        "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/739622?\"\n",
        "    },\n",
        "    \"repo\": {\n",
        "        \"id\": 23934080,\n",
        "        \"name\": \"Early-Modern-OCR/emop-dashboard\",\n",
        "    \"url\": \"https://api.github.com/repos/Early-Modern-OCR/emop-dashboard\"\n",
        "    },\n",
        "    \"payload\": {\n",
        "        \"ref\": \"development\",\n",
        "        \"ref_type\": \"branch\",\n",
        "        \"master-branch\": \"master\",\n",
        "        \"description\": \"\",\n",
        "        \"pusher_type\": \"user\",\n",
        "    },\n",
        "    \"public\": true,\n",
        "    \"created_at\": \"2015-03-01T00:00:00Z\",\n",
        "    \"org\": {\n",
        "        \"id\": 10965476,\n",
        "        \"login\": \"Early-Modern-OCR\",\n",
        "        \"gravatar_id\": \"\",\n",
        "        \"url\": \"https://api.github.com/orgs/Early-Modern-OCR\",\n",
        "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/10965476?\"\n",
        "    }\n",
        "}`\n",
        "\n",
        "This log entry has `CreateEvent` type and its `payload.ref_type` is `branch` . So someone named \"treydock\" (`actor.login`) created a repository branch called \"development\" (`payload.ref`) in the first second of March 1, 2015 (`created_at`) .\n",
        "\n",
        "1. Load the json file as spark dataframe \n",
        "\n",
        "2. Filter this dataframe to retain only those rows that represent push activities (where `type` equals `PushEvent`)\n",
        "\n",
        "3. Count the number of push events.\n",
        "\n",
        "4. Compute the number of push events, grouped per `actor.login`. \n",
        "\n",
        "5. Retrieve the results of (4) in sorted order, where logins with higher number of pushes come first. Retrieve the 10 first such results (which contain the highest number of pushes)\n",
        "\n",
        "6. You are representing a company and need to retrieve the number of pushes for every employee in the company. The file `data/github/employees.txt` contains a list of all employee login names at your company.\n",
        "\n",
        "Extra: if you want to experiment with larger datasets, download more log data from the github archive website and re-do the exercises above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRdQ_TdLJdE1"
      },
      "source": [
        "<font color='violet'>1. Load the json file as spark dataframe: </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4-Sj2KXHPaY",
        "outputId": "b395c248-728c-4f41-b8e9-5e318bbea267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+-------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
            "|actor                                                                                                               |created_at          |id        |org                                                                                                                            |payload                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |public|repo                                                                                                                                 |type       |\n",
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+-------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
            "|{https://avatars.githubusercontent.com/u/739622?, , 739622, treydock, https://api.github.com/users/treydock}        |2015-03-01T00:00:00Z|2614896652|{https://avatars.githubusercontent.com/u/10965476?, , 10965476, Early-Modern-OCR, https://api.github.com/orgs/Early-Modern-OCR}|{null, null, null, null, , null, null, null, null, master, null, null, null, null, null, user, development, branch, null, null}                                                                                                                                                                                                                                                                                                                                                     |true  |{23934080, Early-Modern-OCR/emop-dashboard, https://api.github.com/repos/Early-Modern-OCR/emop-dashboard}                            |CreateEvent|\n",
            "|{https://avatars.githubusercontent.com/u/9063348?, , 9063348, bezerrathm, https://api.github.com/users/bezerrathm}  |2015-03-01T00:00:00Z|2614896653|null                                                                                                                           |{null, 6dda286a3a1c254184f1456b5fefc139ff9dce66, null, [{{ba1618c3d509021c3c759fa9aad031c4a38fe046@gmail.com, Thiago Henrique Menêses Bezerra}, true, Create other.h, 570ad890d78525dfc10364901c41b8236e2c783a, https://api.github.com/repos/bezerrathm/HuffmanCoding/commits/570ad890d78525dfc10364901c41b8236e2c783a}], null, 1, null, 570ad890d78525dfc10364901c41b8236e2c783a, null, null, null, null, null, null, 588068425, null, refs/heads/master, null, null, 1}           |true  |{31481156, bezerrathm/HuffmanCoding, https://api.github.com/repos/bezerrathm/HuffmanCoding}                                          |PushEvent  |\n",
            "|{https://avatars.githubusercontent.com/u/2474382?, , 2474382, demianborba, https://api.github.com/users/demianborba}|2015-03-01T00:00:00Z|2614896654|null                                                                                                                           |{null, 6089ce1d78dc0a028b9f43be86393f7b86d7441e, null, [{{81f8c769cbc39e5504763fee38d8c8c75529d125@actioncreations.com, Demian Borba}, true, update readme, 191a22b798fdf37e9fa87d5bbb37d4e4b5140ca8, https://api.github.com/repos/demianborba/demo-bh-la-braintree-node-angular/commits/191a22b798fdf37e9fa87d5bbb37d4e4b5140ca8}], null, 1, null, 191a22b798fdf37e9fa87d5bbb37d4e4b5140ca8, null, null, null, null, null, null, 588068427, null, refs/heads/master, null, null, 1}|true  |{31475673, demianborba/demo-bh-la-braintree-node-angular, https://api.github.com/repos/demianborba/demo-bh-la-braintree-node-angular}|PushEvent  |\n",
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+-------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gitDF = spark.read.json('data/github/2015-03-01-0.json.gz')\n",
        "gitDF.show(3,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV-05daxJfDU"
      },
      "source": [
        "<font color='violet'> 2. Filter this dataframe to retain only those rows that represent push activities (where type equals PushEvent).\n",
        "\n",
        "Again, sorting is not strictly needed:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX6iXShzIBUp",
        "outputId": "142b6f88-f7f9-404a-cbdc-ad339a75f18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------+---------+\n",
            "|actor                                                                                                               |created_at          |id        |org |payload                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |public|repo                                                                                   |type     |\n",
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------+---------+\n",
            "|{https://avatars.githubusercontent.com/u/4584144?, , 4584144, 0000marcell, https://api.github.com/users/0000marcell}|2015-03-01T00:31:51Z|2614921736|null|{null, 8a3b9fbbb7445ae809a6441414d6989112fd20e6, null, [{{3b41845c55bd0cbc15aa56425f563af645db6204@gmail.com, Marcell Monteiro Cruz}, true, coffee-script implemented, 1bc3f18a8ccc5bd51f4568533af3530a14511252, https://api.github.com/repos/0000marcell/BLANK_SITE/commits/1bc3f18a8ccc5bd51f4568533af3530a14511252}], null, 1, null, 1bc3f18a8ccc5bd51f4568533af3530a14511252, null, null, null, null, null, null, 588078540, null, refs/heads/master, null, null, 1}             |true  |{31145226, 0000marcell/BLANK_SITE, https://api.github.com/repos/0000marcell/BLANK_SITE}|PushEvent|\n",
            "|{https://avatars.githubusercontent.com/u/7462135?, , 7462135, 01000101, https://api.github.com/users/01000101}      |2015-03-01T00:30:19Z|2614920641|null|{null, 2e6410476d923554680abbd17db6e1d8bed28b1c, null, [{{27bc267138cd2af758dc9d89b4908c73da379352@gmail.com, Joshua Cornutt}, true, Changed presentation of clicks left for groups, 5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d, https://api.github.com/repos/joshtipton28/elocator/commits/5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d}], null, 1, null, 5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d, null, null, null, null, null, null, 588078053, null, refs/heads/master, null, null, 1}|true  |{28792932, joshtipton28/elocator, https://api.github.com/repos/joshtipton28/elocator}  |PushEvent|\n",
            "|{https://avatars.githubusercontent.com/u/5255678?, , 5255678, 05K4R1N, https://api.github.com/users/05K4R1N}        |2015-03-01T00:05:15Z|2614902080|null|{null, 47a0ed9e4517e184daa60af603812a4a93a69bb5, null, [{{ab83d1206a9cc03d66b45fd9a688047d192b7ffb@hotmail.com, 05K4R1N}, true, Cambiando interfaz..., b54127ecb5542d9d668e0d7d45ab244cc9240101, https://api.github.com/repos/05K4R1N/Hospital/commits/b54127ecb5542d9d668e0d7d45ab244cc9240101}], null, 1, null, b54127ecb5542d9d668e0d7d45ab244cc9240101, null, null, null, null, null, null, 588070349, null, refs/heads/registrando_pacientes, null, null, 1}                    |true  |{30512343, 05K4R1N/Hospital, https://api.github.com/repos/05K4R1N/Hospital}            |PushEvent|\n",
            "+--------------------------------------------------------------------------------------------------------------------+--------------------+----------+----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------------------------------------------------------------------------------+---------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gitDF.filter(gitDF.type == \"PushEvent\").sort(\"actor.login\").show(3,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwTbW0RkJ3JX"
      },
      "source": [
        "<font color='violet'>3. Count the number of push events:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkm5NbqAIsWv",
        "outputId": "65d79218-db5f-4236-f099-f86a8eefbb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|count|\n",
            "+-----+\n",
            "| 8793|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gitDF.filter(gitDF.type == \"PushEvent\").groupby().count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDBTAC8DJ8jY"
      },
      "source": [
        "\n",
        "<font color='violet'> 4. Compute the number of push events, grouped per `actor.login`.\n",
        "\n",
        "Again, sorting is not strictly needed:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd_ALdmDI-vH",
        "outputId": "527e2221-3514-4d22-a550-491848140f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|      login|count|\n",
            "+-----------+-----+\n",
            "|0000marcell|    1|\n",
            "|   01000101|    1|\n",
            "|    05K4R1N|    2|\n",
            "+-----------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gitDF.filter(gitDF.type == \"PushEvent\").groupby(\"actor.login\").count().sort(\"actor.login\").show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktVmLrbCKCWJ"
      },
      "source": [
        "<font color='violet'>5. Retrieve the results of (4) in sorted order, where logins with higher number of pushes come first. Retrieve the 10 first such results (which contain the highest number of pushes):</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu2uSsjtJiUY",
        "outputId": "29c54c87-78c5-4ebe-acac-3e1512f9af4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|             login|count|\n",
            "+------------------+-----+\n",
            "|      greatfirebot|  192|\n",
            "|diversify-exp-user|  146|\n",
            "|     KenanSulayman|   72|\n",
            "|        manuelrp07|   45|\n",
            "|    mirror-updates|   42|\n",
            "|     tryton-mirror|   37|\n",
            "|           Somasis|   26|\n",
            "|   direwolf-github|   24|\n",
            "|   EmanueleMinotto|   22|\n",
            "|           hansliu|   21|\n",
            "+------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gitDF.filter(gitDF.type == \"PushEvent\").groupby(\"actor.login\").count().sort(\"count\",ascending=False).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lybZ0QBwKYk3"
      },
      "source": [
        "<font color='violet'> 6. You are representing a company and need to retrieve the number of pushes for every employee in the company. The file `data/github/employees.txt` contains a list of all employee login names at your company.\n",
        "\n",
        "IMPORTANT: All the employees in the file `data/github/employees.txt` seem to have at least one push. I have added additional employees with zero pushes to make sure my code is robust:\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqc3_t-HKJ5X",
        "outputId": "92b6ebd3-5a83-4afe-e7f1-64e7b9e805d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+\n",
            "|employee                         |\n",
            "+---------------------------------+\n",
            "|AiMadobe                         |\n",
            "|Akkyie                           |\n",
            "|An employee with zero pushes     |\n",
            "|Another employee with zero pushes|\n",
            "|BatMiles                         |\n",
            "+---------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema3 = \"employee STRING\"\n",
        "employeeDF = spark.read.option(\"delimiter\", \",\").csv('data/github/employees.txt', schema=schema3)\n",
        "newRow = spark.createDataFrame([('An employee with zero pushes',),('Another employee with zero pushes',)],schema=schema3)\n",
        "employeeDF = employeeDF.union(newRow)\n",
        "employeeDF.sort(\"employee\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw0uImHiPFHW"
      },
      "source": [
        "<font color='violet'>Notice lack of zero push employee:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj5cvMCXK66J",
        "outputId": "99722fc5-4ebd-4017-8c2f-e0a57db55476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|   employee|count|\n",
            "+-----------+-----+\n",
            "|   Tookmund|    1|\n",
            "|  gvincenzi|    1|\n",
            "|JustScience|    1|\n",
            "+-----------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pushersDF = gitDF.filter(gitDF.type == \"PushEvent\").join(employeeDF, gitDF.actor.login == employeeDF.employee).groupBy(\"employee\").count().sort(\"count\",ascending=True)\n",
        "pushersDF.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ZMwuJr3geQ"
      },
      "source": [
        "<font color='violet'>We can find the employees with zero pushes:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-B1hKDg07vo",
        "outputId": "cfb0069a-793b-4bed-f7ff-6ca01e62f85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+-----+\n",
            "|employee                         |count|\n",
            "+---------------------------------+-----+\n",
            "|An employee with zero pushes     |0    |\n",
            "|Another employee with zero pushes|0    |\n",
            "+---------------------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "nopushersDF = employeeDF.join(gitDF, employeeDF.employee == gitDF.actor.login, 'left_anti').withColumn(\"count\", lit(0))\n",
        "nopushersDF.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIW-HZj83qWI"
      },
      "source": [
        "<font color='violet'>Join the two together for the correct output. Sorting is not strictly necessary:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO6ptRP71iqf",
        "outputId": "0645ef3e-dd49-4493-8597-f4f0ecf86dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------+-----+\n",
            "|employee                         |count|\n",
            "+---------------------------------+-----+\n",
            "|An employee with zero pushes     |0    |\n",
            "|Another employee with zero pushes|0    |\n",
            "|Gix075                           |1    |\n",
            "|JustScience                      |1    |\n",
            "|Tookmund                         |1    |\n",
            "|serranoarevalo                   |1    |\n",
            "|jbernie2                         |1    |\n",
            "|gvincenzi                        |1    |\n",
            "|summersd                         |1    |\n",
            "|whh8b                            |1    |\n",
            "|IrinaDmt                         |1    |\n",
            "|listingslab                      |1    |\n",
            "|gkop                             |1    |\n",
            "|WhiteHalmos                      |1    |\n",
            "|jinmingmu                        |1    |\n",
            "|nesteves                         |1    |\n",
            "|makjona                          |1    |\n",
            "|Juxnist                          |1    |\n",
            "|dpyryesk                         |1    |\n",
            "|aclindsa                         |1    |\n",
            "+---------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pushersDF.union(nopushersDF).sort(\"count\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFHCps7N48a0",
        "outputId": "193569a6-6a55-4c45-f2ab-2f8291720a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|employee     |count|\n",
            "+-------------+-----+\n",
            "|KenanSulayman|72   |\n",
            "|manuelrp07   |45   |\n",
            "|Somasis      |26   |\n",
            "+-------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pushersDF.union(nopushersDF).sort(\"count\",ascending=False).show(3,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ajB6DmJJBWN"
      },
      "source": [
        "<font color='violet'>Stopping Spark:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BxoNBEOfNqmb"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}