{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qJy5XoByTKn"
      },
      "source": [
        "# Exercises on Spark Core API\n",
        "<font color='violet'>Any changes to the notebook text made for the homework assignment are indicated in violet.</font>\n",
        "\n",
        "This notebook contains exercises on three different datasets. The goal is to solve these exercises using the **Spark Core API**.\n",
        "\n",
        "We start by installing pyspark (only execute if this is needed, e.g., if you are running this on Google Colab), and downloading the datasets. The exercises follow.\n",
        "\n",
        "### Useful documentation to do these exercises.\n",
        "\n",
        "The PySpark Documentation is available at https://spark.apache.org/docs/latest/api/python/index.html. \n",
        "\n",
        "Instructions on how to install PySpark on your local PC may be found at https://spark.apache.org/docs/latest/api/python/getting_started/install.html. Note that by installing PySpark in this way, you automatically have a local copy of Spark.\n",
        "\n",
        "The Spark Core  api that we use below has the following  documentation which is a useful reference to have: https://spark.apache.org/docs/latest/api/python/reference/pyspark.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPDnAZE9us6F"
      },
      "source": [
        "#### Installing PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z5Xe86sus6F",
        "outputId": "952ac691-2601-4180-eed2-01e78d20af76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=cacedca3a145da50c67f00b399f6cdc343e216dd24317b31286543e05d2aa25d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "# This installs pyspark in the current python environment.\n",
        "# By installing pyspark, we automatically also install spark.\n",
        "# You **need** to run this cell when running this notebook in google colab\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvPogFL6us6H"
      },
      "source": [
        "#### General imports and starting Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DP9Uj34dus6I"
      },
      "outputs": [],
      "source": [
        "#This is needed to start a Spark session from the notebook\n",
        "#You may adjust the memory used by the driver program based on your machine's settings\n",
        "import os \n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=3g  pyspark-shell\"\n",
        "\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "kYOmJ0njus6J",
        "outputId": "a1420260-d31f-4a18-b53f-0b811f3afce0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=demoRDD>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3c2dace34f25:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demoRDD</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# Start Spark in LOCAL mode\n",
        "# -------------------------------\n",
        "\n",
        "#The following lines are just there to allow this cell to be re-executed multiple times:\n",
        "#if a spark session was already started, we stop it before starting a new one\n",
        "#(there can be only one spark context per jupyter notebook)\n",
        "try: \n",
        "    spark\n",
        "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
        "    spark.stop()\n",
        "except: \n",
        "    pass\n",
        "\n",
        "# Create a new spark session (note, the * indicates to use all available CPU cores)\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"demoRDD\") \\\n",
        "    .getOrCreate()\n",
        "    \n",
        "#When dealing with RDDs, we work the sparkContext object. See https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext\n",
        "sc=spark.sparkContext\n",
        "\n",
        "# We print the sparkcontext. This prints general information about the spark instance we have connected to. \n",
        "# In particular, the hyperlink allows us to open the spark UI (useful for seeing what is going on)\n",
        "# Note: this hyperlink won't work when running this notebook in Google Colab.\n",
        "sc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55F4k_N-wgmZ"
      },
      "source": [
        "### Downloading data\n",
        "\n",
        "The next cell downloads the data required to do the exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSHIau9kwkD-",
        "outputId": "b4e88722-53e6-407f-f7c3-48fe37bba520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 19:32:19--  https://drive.google.com/u/0/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.114.101, 172.253.114.139, 172.253.114.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.114.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download [following]\n",
            "--2023-03-31 19:32:19--  https://drive.google.com/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-50-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i301kdqge3ojlpgpjtot6uqccfg4ef01/1680291075000/12785547293638390956/*/1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS?e=download&uuid=753cb20f-0633-4a5e-a604-2ccdc5bee5b5 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-31 19:32:26--  https://doc-0o-50-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i301kdqge3ojlpgpjtot6uqccfg4ef01/1680291075000/12785547293638390956/*/1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS?e=download&uuid=753cb20f-0633-4a5e-a604-2ccdc5bee5b5\n",
            "Resolving doc-0o-50-docs.googleusercontent.com (doc-0o-50-docs.googleusercontent.com)... 142.250.1.132, 2607:f8b0:4001:c24::84\n",
            "Connecting to doc-0o-50-docs.googleusercontent.com (doc-0o-50-docs.googleusercontent.com)|142.250.1.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15656709 (15M) [application/zip]\n",
            "Saving to: ‘downloads/data-spark-exercises.zip’\n",
            "\n",
            "downloads/data-spar 100%[===================>]  14.93M  57.7MB/s    in 0.3s    \n",
            "\n",
            "2023-03-31 19:32:27 (57.7 MB/s) - ‘downloads/data-spark-exercises.zip’ saved [15656709/15656709]\n",
            "\n",
            "books  github  movielens  sensors\n"
          ]
        }
      ],
      "source": [
        "!mkdir downloads\n",
        "!wget 'https://drive.google.com/u/0/uc?id=1Xlmwiku1RKLyACAPMFZMg1-RsWY-8tYS&export=download' -O downloads/data-spark-exercises.zip\n",
        "!unzip -q downloads/data-spark-exercises.zip\n",
        "!ls data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNlBVQqyTKp"
      },
      "source": [
        "## 1. Sensor data exercises\n",
        "In the file “data/sensors/sensor-sample.txt” you will find on each line, multiple fields of information, let’s call them : Date(Date), Time(Time), RoomId(Integer)-SensorId(Integer), Value1(float), Value2(float)\n",
        "Using this file, use spark to compute the following queries :\n",
        "\n",
        "1. Count the number of entries for each day.\n",
        "2. Count the number of measures for each pair of RoomId-SensorId.\n",
        "3. Compute the average of Value1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWvfySle1VE-"
      },
      "source": [
        "<font color='violet'>Reading in the data:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PZg_Ljue3CN",
        "outputId": "22a81397-6881-4a73-9b9c-989657a7d298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2017-03-31', '03:38:16.508', '1-0', '122.153', '2.03397'],\n",
              " ['2017-03-31', '03:38:15.967', '1-1', '-3.91901', '2.09397'],\n",
              " ['2017-03-31', '03:38:16.577', '1-2', '11.04', '2.07397']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "fileName = 'data/sensors/sensor-sample.txt'\n",
        "sensorRDD = sc.textFile(fileName)\n",
        "sensorRDD = sensorRDD.map(lambda x: x.split())\n",
        "sensorRDD.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shaBtUS5h08q"
      },
      "source": [
        "<font color='violet'>1. Count the number of entries for each day:</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ja-84mMfvUB",
        "outputId": "7390660d-c711-418a-8013-ab9e95227bb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'2017-03-31': 3393,\n",
              "             '2017-02-28': 62103,\n",
              "             '2017-03-01': 33423,\n",
              "             '2017-03-02': 32403,\n",
              "             '2017-03-03': 29727,\n",
              "             '2017-03-04': 30225,\n",
              "             '2017-03-05': 26019,\n",
              "             '2017-03-06': 24315,\n",
              "             '2017-03-07': 26625,\n",
              "             '2017-03-08': 29343,\n",
              "             '2017-03-09': 27288,\n",
              "             '2017-03-21': 19410,\n",
              "             '2017-03-22': 10989,\n",
              "             '2017-03-10': 12483,\n",
              "             '2017-03-23': 24213,\n",
              "             '2017-03-24': 13467,\n",
              "             '2017-03-11': 19059,\n",
              "             '2017-03-12': 25089,\n",
              "             '2017-03-25': 12225,\n",
              "             '2017-03-13': 24783,\n",
              "             '2017-03-26': 13587,\n",
              "             '2017-03-14': 23418,\n",
              "             '2017-03-27': 14544,\n",
              "             '2017-03-15': 11901,\n",
              "             '2017-03-28': 22338,\n",
              "             '2017-03-29': 12120,\n",
              "             '2017-03-16': 13869,\n",
              "             '2017-03-17': 26922,\n",
              "             '2017-03-30': 5814,\n",
              "             '2017-03-18': 17427,\n",
              "             '2017-03-19': 21999,\n",
              "             '2017-03-20': 21942,\n",
              "             '2017-04-01': 537})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dayRDD = sensorRDD.map(lambda x: x[0]).countByValue()\n",
        "dayRDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag6wLiAp1amq"
      },
      "source": [
        "<font color='violet'>\n",
        "The sorting is not strictly necessary, but helps verify the correctness of the result, and comparison with notebook 4:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNKvLY251Z3C",
        "outputId": "58e88fa7-c015-4e66-ee40-0fece78d3709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2017-02-28': 62103,\n",
              " '2017-03-01': 33423,\n",
              " '2017-03-02': 32403,\n",
              " '2017-03-03': 29727,\n",
              " '2017-03-04': 30225,\n",
              " '2017-03-05': 26019,\n",
              " '2017-03-06': 24315,\n",
              " '2017-03-07': 26625,\n",
              " '2017-03-08': 29343,\n",
              " '2017-03-09': 27288,\n",
              " '2017-03-10': 12483,\n",
              " '2017-03-11': 19059,\n",
              " '2017-03-12': 25089,\n",
              " '2017-03-13': 24783,\n",
              " '2017-03-14': 23418,\n",
              " '2017-03-15': 11901,\n",
              " '2017-03-16': 13869,\n",
              " '2017-03-17': 26922,\n",
              " '2017-03-18': 17427,\n",
              " '2017-03-19': 21999,\n",
              " '2017-03-20': 21942,\n",
              " '2017-03-21': 19410,\n",
              " '2017-03-22': 10989,\n",
              " '2017-03-23': 24213,\n",
              " '2017-03-24': 13467,\n",
              " '2017-03-25': 12225,\n",
              " '2017-03-26': 13587,\n",
              " '2017-03-27': 14544,\n",
              " '2017-03-28': 22338,\n",
              " '2017-03-29': 12120,\n",
              " '2017-03-30': 5814,\n",
              " '2017-03-31': 3393,\n",
              " '2017-04-01': 537}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "myKeys = list(dayRDD.keys())\n",
        "myKeys.sort()\n",
        "{i: dayRDD[i] for i in myKeys}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tTz2ahqjGwz"
      },
      "source": [
        "<font color='violet'>2. Count the number of measures for each pair of RoomId-SensorId:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YDsIMStFjFxo"
      },
      "outputs": [],
      "source": [
        "roomsensorRDD = sensorRDD.map(lambda x: x[2]).countByValue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl6xGRFU2PC-"
      },
      "source": [
        "<font color='violet'>Again, sorting is not stirctly needed:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dRPOZPl2Gl5",
        "outputId": "d46db334-1bc7-45a9-eaa7-fd3628d481d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1-0': 43047,\n",
              " '1-1': 43047,\n",
              " '1-2': 43047,\n",
              " '2-0': 46915,\n",
              " '2-1': 46915,\n",
              " '2-2': 46915,\n",
              " '3-0': 46634,\n",
              " '3-1': 46634,\n",
              " '3-2': 46634,\n",
              " '4-0': 43793,\n",
              " '4-1': 43793,\n",
              " '4-2': 43793,\n",
              " '5-0': 35,\n",
              " '5-1': 35,\n",
              " '5-2': 35,\n",
              " '6-0': 35666,\n",
              " '6-1': 35666,\n",
              " '6-2': 35666,\n",
              " '7-0': 14910,\n",
              " '7-1': 14910,\n",
              " '7-2': 14910}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "myKeys = list(roomsensorRDD.keys())\n",
        "myKeys.sort()\n",
        "{i: roomsensorRDD[i] for i in myKeys}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tef7BKbgjnle"
      },
      "source": [
        "<font color='violet'>3. Compute the average of Value1:\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y0hSLjlj13E",
        "outputId": "1acc4d59-b2e3-4d2a-ec0c-98de6f8b546b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.8069927576456"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sensorRDD.map(lambda x: float(x[3])).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwxpq5_NyTKv"
      },
      "source": [
        "## 2. Movielens movie data exercises\n",
        "\n",
        "Movielens (https://movielens.org/) is a website that provides non-commercial, personalised movie recommendations. GroupLens Research has collected and made available rating data sets from the MovieLens web site for the purpose of research into making recommendation services. In this exercise, we will use one of these datasets (the movielens latest dataset, http://files.grouplens.org/datasets/movielens/ml-latest-small.zip) and compute some basic queries on it.\n",
        "The dataset has already been downloaded and is available at data/movielens/movies.csv, data/movielens/ratings.csv, data/movielens/tags.csv, data/movielens/links.csv\n",
        "\n",
        "1. Inspect the dataset's [README file](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html), in particular the section titled \"Content and Use of Files\" to learn the structure of these three files.\n",
        "2. Compute all pairs (`movieid`, `rat`) where `movieid` is a movie id (as found in ratings.csv) and `rat` is the average rating of that movie id. (Hint: use aggregateByKey to compute first the sum of all ratings as well as the number of ratings per key).\n",
        "2. Compute all pairs (`title`, `rat`) where `title` is a full movie title (as found in the movies.csv file), and `rat` is the average rating of that movie (computed over all possible ratings for that movie, as found in the ratings.csv file)\n",
        "3. [_Extra_] Compute all pairs (`title`, `tag`) where `title` is a full movie title that has an average rating of at least 3.5, and `tag` is a tag for that movie (as found in the tags.csv file)\n",
        "\n",
        "Extra: if you want to experiment with larger datasets, download the 10m dataset (http://files.grouplens.org/datasets/movielens/ml-10m.zip, 250 Mb uncompressed) and re-do the exercises above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNYu-4n4qjtV"
      },
      "source": [
        "<font color='violet'> 1. Inspect the dataset's README file, in particular the section titled \"Content and Use of Files\" to learn the structure of these three files:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff9sXmRNpgUk",
        "outputId": "86af3b19-240d-4e47-9449-324a54b848b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary\n",
            "\n",
            "=======\n",
            "\n",
            "\n",
            "\n",
            "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
            "\n",
            "\n",
            "\n",
            "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
            "\n",
            "\n",
            "\n",
            "The data are contained in the files `links.csv`, `movies.csv`, `ratings.csv` and `tags.csv`. More details about the contents and use of all these files follows.\n",
            "\n",
            "\n",
            "\n",
            "This is a *development* dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available *benchmark* datasets if that is your intent.\n",
            "\n",
            "\n",
            "\n",
            "This and other GroupLens data sets are publicly available for download at <http://grouplens.org/datasets/>.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Usage License\n",
            "\n",
            "=============\n",
            "\n",
            "\n",
            "\n",
            "Neither the University of Minnesota nor any of the researchers involved can guarantee the correctness of the data, its suitability for any particular purpose, or the validity of results based on the use of the data set. The data set may be used for any research purposes under the following conditions:\n",
            "\n",
            "\n",
            "\n",
            "* The user may not state or imply any endorsement from the University of Minnesota or the GroupLens Research Group.\n",
            "\n",
            "* The user must acknowledge the use of the data set in publications resulting from the use of the data set (see below for citation information).\n",
            "\n",
            "* The user may redistribute the data set, including transformations, so long as it is distributed under these same license conditions.\n",
            "\n",
            "* The user may not use this information for any commercial or revenue-bearing purposes without first obtaining permission from a faculty member of the GroupLens Research Project at the University of Minnesota.\n",
            "\n",
            "* The executable software scripts are provided \"as is\" without warranty of any kind, either expressed or implied, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose. The entire risk as to the quality and performance of them is with you. Should the program prove defective, you assume the cost of all necessary servicing, repair or correction.\n",
            "\n",
            "\n",
            "\n",
            "In no event shall the University of Minnesota, its affiliates or employees be liable to you for any damages arising out of the use or inability to use these programs (including but not limited to loss of data or data being rendered inaccurate).\n",
            "\n",
            "\n",
            "\n",
            "If you have any further questions or comments, please email <grouplens-info@umn.edu>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Citation\n",
            "\n",
            "========\n",
            "\n",
            "\n",
            "\n",
            "To acknowledge use of the dataset in publications, please cite the following paper:\n",
            "\n",
            "\n",
            "\n",
            "> F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Further Information About GroupLens\n",
            "\n",
            "===================================\n",
            "\n",
            "\n",
            "\n",
            "GroupLens is a research group in the Department of Computer Science and Engineering at the University of Minnesota. Since its inception in 1992, GroupLens's research projects have explored a variety of fields including:\n",
            "\n",
            "\n",
            "\n",
            "* recommender systems\n",
            "\n",
            "* online communities\n",
            "\n",
            "* mobile and ubiquitious technologies\n",
            "\n",
            "* digital libraries\n",
            "\n",
            "* local geographic information systems\n",
            "\n",
            "\n",
            "\n",
            "GroupLens Research operates a movie recommender based on collaborative filtering, MovieLens, which is the source of these data. We encourage you to visit <http://movielens.org> to try it out! If you have exciting ideas for experimental work to conduct on MovieLens, send us an email at <grouplens-info@cs.umn.edu> - we are always interested in working with external collaborators.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Content and Use of Files\n",
            "\n",
            "========================\n",
            "\n",
            "\n",
            "\n",
            "Formatting and Encoding\n",
            "\n",
            "-----------------------\n",
            "\n",
            "\n",
            "\n",
            "The dataset files are written as [comma-separated values](http://en.wikipedia.org/wiki/Comma-separated_values) files with a single header row. Columns that contain commas (`,`) are escaped using double-quotes (`\"`). These files are encoded as UTF-8. If accented characters in movie titles or tag values (e.g. Misérables, Les (1995)) display incorrectly, make sure that any program reading the data, such as a text editor, terminal, or script, is configured for UTF-8.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "User Ids\n",
            "\n",
            "--------\n",
            "\n",
            "\n",
            "\n",
            "MovieLens users were selected at random for inclusion. Their ids have been anonymized. User ids are consistent between `ratings.csv` and `tags.csv` (i.e., the same id refers to the same user across the two files).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Movie Ids\n",
            "\n",
            "---------\n",
            "\n",
            "\n",
            "\n",
            "Only movies with at least one rating or tag are included in the dataset. These movie ids are consistent with those used on the MovieLens web site (e.g., id `1` corresponds to the URL <https://movielens.org/movies/1>). Movie ids are consistent between `ratings.csv`, `tags.csv`, `movies.csv`, and `links.csv` (i.e., the same id refers to the same movie across these four data files).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ratings Data File Structure (ratings.csv)\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
            "\n",
            "\n",
            "\n",
            "    userId,movieId,rating,timestamp\n",
            "\n",
            "\n",
            "\n",
            "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
            "\n",
            "\n",
            "\n",
            "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
            "\n",
            "\n",
            "\n",
            "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tags Data File Structure (tags.csv)\n",
            "\n",
            "-----------------------------------\n",
            "\n",
            "\n",
            "\n",
            "All tags are contained in the file `tags.csv`. Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\n",
            "\n",
            "\n",
            "\n",
            "    userId,movieId,tag,timestamp\n",
            "\n",
            "\n",
            "\n",
            "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
            "\n",
            "\n",
            "\n",
            "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\n",
            "\n",
            "\n",
            "\n",
            "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Movies Data File Structure (movies.csv)\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
            "\n",
            "\n",
            "\n",
            "    movieId,title,genres\n",
            "\n",
            "\n",
            "\n",
            "Movie titles are entered manually or imported from <https://www.themoviedb.org/>, and include the year of release in parentheses. Errors and inconsistencies may exist in these titles.\n",
            "\n",
            "\n",
            "\n",
            "Genres are a pipe-separated list, and are selected from the following:\n",
            "\n",
            "\n",
            "\n",
            "* Action\n",
            "\n",
            "* Adventure\n",
            "\n",
            "* Animation\n",
            "\n",
            "* Children's\n",
            "\n",
            "* Comedy\n",
            "\n",
            "* Crime\n",
            "\n",
            "* Documentary\n",
            "\n",
            "* Drama\n",
            "\n",
            "* Fantasy\n",
            "\n",
            "* Film-Noir\n",
            "\n",
            "* Horror\n",
            "\n",
            "* Musical\n",
            "\n",
            "* Mystery\n",
            "\n",
            "* Romance\n",
            "\n",
            "* Sci-Fi\n",
            "\n",
            "* Thriller\n",
            "\n",
            "* War\n",
            "\n",
            "* Western\n",
            "\n",
            "* (no genres listed)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Links Data File Structure (links.csv)\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Identifiers that can be used to link to other sources of movie data are contained in the file `links.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
            "\n",
            "\n",
            "\n",
            "    movieId,imdbId,tmdbId\n",
            "\n",
            "\n",
            "\n",
            "movieId is an identifier for movies used by <https://movielens.org>. E.g., the movie Toy Story has the link <https://movielens.org/movies/1>.\n",
            "\n",
            "\n",
            "\n",
            "imdbId is an identifier for movies used by <http://www.imdb.com>. E.g., the movie Toy Story has the link <http://www.imdb.com/title/tt0114709/>.\n",
            "\n",
            "\n",
            "\n",
            "tmdbId is an identifier for movies used by <https://www.themoviedb.org>. E.g., the movie Toy Story has the link <https://www.themoviedb.org/movie/862>.\n",
            "\n",
            "\n",
            "\n",
            "Use of the resources listed above is subject to the terms of each provider.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Cross-Validation\n",
            "\n",
            "----------------\n",
            "\n",
            "\n",
            "\n",
            "Prior versions of the MovieLens dataset included either pre-computed cross-folds or scripts to perform this computation. We no longer bundle either of these features with the dataset, since most modern toolkits provide this as a built-in feature. If you wish to learn about standard approaches to cross-fold computation in the context of recommender systems evaluation, see [LensKit](http://lenskit.org) for tools, documentation, and open-source code examples.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "readme = 'data/movielens/README.txt'\n",
        "file_obj = open(readme, \"r\")\n",
        "for line in file_obj:\n",
        "  print(line)\n",
        "file_obj.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD4AYyw9Ulw4"
      },
      "source": [
        "<font color='violet'>Reading in data:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h61kuEI9tJUH",
        "outputId": "71edcc8b-169f-4308-a5ee-f429c08358dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1', '1', '4.0', '964982703'],\n",
              " ['1', '3', '4.0', '964981247'],\n",
              " ['1', '6', '4.0', '964982224']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "fileName = 'data/movielens/ratings.csv'\n",
        "ratingsRDD = sc.textFile(fileName)\n",
        "ratingsRDD = ratingsRDD.map(lambda x:x.split(\",\"))\n",
        "ratingsRDD.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kVcUWvFTNgv"
      },
      "source": [
        "<font color='violet'>Notice the commas present in the movie titles, and the additional quotes for the 11th movie:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZThfxyqNdFU",
        "outputId": "b00c31f1-136b-450b-d449-cfa5f665229d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n",
              " '2,Jumanji (1995),Adventure|Children|Fantasy',\n",
              " '3,Grumpier Old Men (1995),Comedy|Romance',\n",
              " '4,Waiting to Exhale (1995),Comedy|Drama|Romance',\n",
              " '5,Father of the Bride Part II (1995),Comedy',\n",
              " '6,Heat (1995),Action|Crime|Thriller',\n",
              " '7,Sabrina (1995),Comedy|Romance',\n",
              " '8,Tom and Huck (1995),Adventure|Children',\n",
              " '9,Sudden Death (1995),Action',\n",
              " '10,GoldenEye (1995),Action|Adventure|Thriller',\n",
              " '11,\"American President, The (1995)\",Comedy|Drama|Romance']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "moviesRDD = sc.textFile('data/movielens/movies.csv')\n",
        "moviesRDD.take(11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXJFmoCTgsM"
      },
      "source": [
        "<font color='violet'>Since using dataframes is not allowed in this notebook, we will have to do some manual parsing of the data. The first comma in each line always separates the movieID from the rest of the line, and the last comma always separates the genre from the rest of the line. We also have the strip extra quotes present in the titles, in particular look at the 11th movie:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGN4AR1k51za",
        "outputId": "21b8dd50-b332-4d6d-e740-0cac321c8d94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1', 'Toy Story (1995)'],\n",
              " ['2', 'Jumanji (1995)'],\n",
              " ['3', 'Grumpier Old Men (1995)'],\n",
              " ['4', 'Waiting to Exhale (1995)'],\n",
              " ['5', 'Father of the Bride Part II (1995)'],\n",
              " ['6', 'Heat (1995)'],\n",
              " ['7', 'Sabrina (1995)'],\n",
              " ['8', 'Tom and Huck (1995)'],\n",
              " ['9', 'Sudden Death (1995)'],\n",
              " ['10', 'GoldenEye (1995)'],\n",
              " ['11', 'American President, The (1995)']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "moviesRDD = moviesRDD.map(lambda x:x.split(\",\",1)).map(lambda x:[x[0],x[1].rsplit(\",\",1)[0].strip('\\\"')])\n",
        "moviesRDD.take(11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoaFaeNYuVd4"
      },
      "source": [
        "<font color='violet'>Similarly, for the tags dataset:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-EK9bzYt_pQ",
        "outputId": "7bc52fbb-e12a-4026-e691-7e7de353f2ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2', '60756', 'funny', '1445714994'],\n",
              " ['2', '60756', 'Highly quotable', '1445714996'],\n",
              " ['2', '60756', 'will ferrell', '1445714992']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tagsRDD = sc.textFile('data/movielens/tags.csv')\n",
        "tagsRDD = tagsRDD.map(lambda x:x.split(\",\"))\n",
        "tagsRDD.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6D420ZNtMm1"
      },
      "source": [
        "<font color='violet'>2. Compute all pairs (movieid, rat) where movieid is a movie id (as found in ratings.csv) and rat is the average rating of that movie id. (Hint: use aggregateByKey to compute first the sum of all ratings as well as the number of ratings per key).\n",
        "\n",
        "<font color='violet'>We make a pair RDD, where the keys are the movieids and the values is a list containing the ratings and the constant number 1. The two elements of this list are then used to calculate the sum of scores and number of reviews by key. The average rating by key can be calculated by dividing these two numbers. Again, sorting is not strictly needed.</font>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os4w04Qetvpt",
        "outputId": "8672304e-563b-46c4-af16-e7dee103bf0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3.9209302325581397),\n",
              " (2, 3.4318181818181817),\n",
              " (3, 3.2596153846153846),\n",
              " (4, 2.357142857142857),\n",
              " (5, 3.0714285714285716)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "pairRDD = ratingsRDD.map(lambda x:(int(x[1]),[float(x[2]),1]))\n",
        "pairRDD.reduceByKey(lambda x,y: [x[0]+y[0],x[1]+y[1]]).mapValues(lambda x:x[0]/x[1]).sortByKey().take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI-o4Anp3xi2"
      },
      "source": [
        "<font color='violet'>3. Compute all pairs (title, rat) where title is a full movie title (as found in the movies.csv file), and rat is the average rating of that movie (computed over all possible ratings for that movie, as found in the ratings.csv file)\n",
        "\n",
        "The averaging is achieved by a similar trick as in the previous exercise, though indexing is a bit more involved here. Again, sorting is not strictly necessary.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EzRxS0Ee6HD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c41d7d-ae12-484a-86a4-01a22fa0421f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', [4.0, 1]), ('3', [4.0, 1]), ('6', [4.0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "pairRDD1 = ratingsRDD.map(lambda x:(x[1],[float(x[2]),1]))\n",
        "pairRDD1.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWvz4yo5_xN",
        "outputId": "210e225a-31d8-480d-be0e-b75cbeab8d5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Toy Story (1995)'),\n",
              " ('2', 'Jumanji (1995)'),\n",
              " ('3', 'Grumpier Old Men (1995)'),\n",
              " ('4', 'Waiting to Exhale (1995)'),\n",
              " ('5', 'Father of the Bride Part II (1995)'),\n",
              " ('6', 'Heat (1995)'),\n",
              " ('7', 'Sabrina (1995)'),\n",
              " ('8', 'Tom and Huck (1995)'),\n",
              " ('9', 'Sudden Death (1995)'),\n",
              " ('10', 'GoldenEye (1995)'),\n",
              " ('11', 'American President, The (1995)')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "pairRDD2 = moviesRDD.map(lambda x:(x[0],x[1]))\n",
        "pairRDD2.take(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SI2g-j47cN9",
        "outputId": "162306eb-45d2-422d-ea30-66ad007ddcfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"'71 (2014)\", 4.0),\n",
              " (\"'Hellboy': The Seeds of Creation (2004)\", 4.0),\n",
              " (\"'Round Midnight (1986)\", 3.5),\n",
              " (\"'Salem's Lot (2004)\", 5.0),\n",
              " (\"'Til There Was You (1997)\", 4.0),\n",
              " (\"'Tis the Season for Love (2015)\", 1.5),\n",
              " (\"'burbs, The (1989)\", 3.176470588235294),\n",
              " (\"'night Mother (1986)\", 3.0),\n",
              " ('(500) Days of Summer (2009)', 3.6666666666666665),\n",
              " ('*batteries not included (1987)', 3.2857142857142856),\n",
              " ('...All the Marbles (1981)', 2.0),\n",
              " ('...And Justice for All (1979)', 3.1666666666666665),\n",
              " ('00 Schneider - Jagd auf Nihil Baxter (1994)', 4.5),\n",
              " ('1-900 (06) (1994)', 4.0),\n",
              " ('10 (1979)', 3.375),\n",
              " ('10 Cent Pistol (2015)', 1.25),\n",
              " ('10 Cloverfield Lane (2016)', 3.6785714285714284),\n",
              " ('10 Items or Less (2006)', 2.6666666666666665),\n",
              " ('10 Things I Hate About You (1999)', 3.5277777777777777),\n",
              " ('10 Years (2011)', 3.5),\n",
              " ('10,000 BC (2008)', 2.7058823529411766),\n",
              " ('100 Girls (2000)', 3.25),\n",
              " ('100 Streets (2016)', 2.5),\n",
              " ('101 Dalmatians (1996)', 3.074468085106383),\n",
              " ('101 Dalmatians (One Hundred and One Dalmatians) (1961)',\n",
              "  3.4318181818181817),\n",
              " (\"101 Dalmatians II: Patch's London Adventure (2003)\", 2.5),\n",
              " ('101 Reykjavik (101 Reykjavík) (2000)', 3.5),\n",
              " ('102 Dalmatians (2000)', 2.7777777777777777),\n",
              " ('10th & Wolf (2006)', 4.5),\n",
              " ('10th Kingdom, The (2000)', 2.75),\n",
              " ('10th Victim, The (La decima vittima) (1965)', 4.0),\n",
              " ('11\\'09\"\"01 - September 11 (2002)', 4.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pairRDD1.join(pairRDD2).reduceByKey(lambda x,y: ([x[0][0]+y[0][0],x[0][1]+y[0][1]],y[1])).map(lambda x:(x[1][1],x[1][0][0]/x[1][0][1])).sortByKey().take(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH5I1psrrhIg"
      },
      "source": [
        "<font color='violet'>4. [_Extra_] Compute all pairs (title, tag) where title is a full movie title that has an average rating of at least 3.5, and tag is a tag for that movie (as found in the tags.csv file)\n",
        "\n",
        "Again, sorting is not strictly needed, and the average rating is only included to verify the that no ratings less than 3.5 are listed.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIUbTJTesVc9",
        "outputId": "a20e181a-24e0-408f-d0ac-31f728922a7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ghost World (2001)', ['adolescence', 3.5]),\n",
              " ('Prince of Egypt, The (1998)', ['Bible', 3.5]),\n",
              " ('Prince of Egypt, The (1998)', ['Moses', 3.5]),\n",
              " ('Babel (2006)', ['Brad Pitt', 3.5]),\n",
              " ('Babel (2006)', ['cate blanchett', 3.5]),\n",
              " ('Babel (2006)', ['multiple storylines', 3.5]),\n",
              " ('Babel (2006)', ['social commentary', 3.5]),\n",
              " ('Father of the Bride (1991)', ['remake', 3.5]),\n",
              " ('Father of the Bride (1991)', ['wedding', 3.5]),\n",
              " ('Owning Mahowny (2003)', ['gambling', 3.5])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "ratingsRDD.map(lambda x:(x[1],[float(x[2]),1]))\\\n",
        "          .reduceByKey(lambda x,y: [x[0]+y[0],x[1]+y[1]])\\\n",
        "          .mapValues(lambda x:x[0]/x[1])\\\n",
        "          .filter(lambda x: x[1] >= 3.5)\\\n",
        "          .join(moviesRDD.map(lambda x:(x[0],x[1])))\\\n",
        "          .join(tagsRDD.map(lambda x:(x[1],x[2])))\\\n",
        "          .map(lambda x: (x[1][0][1],[x[1][1],x[1][0][0]]))\\\n",
        "          .sortBy(lambda x:x[1][1])\\\n",
        "          .take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHDM49PyTKx"
      },
      "source": [
        "## 3. Github log data exercises\n",
        "Github makes activity logs publicly available at https://www.githubarchive.org/. One such log file, which contains activity data for 2015-03-01 between 0h-1h at night, has been downloaded and is available at `data/github/2015-03-01-0.json.gz`. This (compressed) file contains multiple JSON objects, one per line. Here is a sample line of this file, neatly formatted:\n",
        "\n",
        "`{ \"id\": \"2614896652\",\n",
        "    \"type\": \"CreateEvent\",\n",
        "    \"actor\": {\n",
        "        \"id\": 739622,\n",
        "        \"login\": \"treydock\",\n",
        "        \"gravatar_id\": \"\",\n",
        "        \"url\": \"https://api.githb.com/users/treydock\",\n",
        "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/739622?\"\n",
        "    },\n",
        "    \"repo\": {\n",
        "        \"id\": 23934080,\n",
        "        \"name\": \"Early-Modern-OCR/emop-dashboard\",\n",
        "    \"url\": \"https://api.github.com/repos/Early-Modern-OCR/emop-dashboard\"\n",
        "    },\n",
        "    \"payload\": {\n",
        "        \"ref\": \"development\",\n",
        "        \"ref_type\": \"branch\",\n",
        "        \"master-branch\": \"master\",\n",
        "        \"description\": \"\",\n",
        "        \"pusher_type\": \"user\",\n",
        "    },\n",
        "    \"public\": true,\n",
        "    \"created_at\": \"2015-03-01T00:00:00Z\",\n",
        "    \"org\": {\n",
        "        \"id\": 10965476,\n",
        "        \"login\": \"Early-Modern-OCR\",\n",
        "        \"gravatar_id\": \"\",\n",
        "        \"url\": \"https://api.github.com/orgs/Early-Modern-OCR\",\n",
        "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/10965476?\"\n",
        "    }\n",
        "}`\n",
        "\n",
        "This log entry has `CreateEvent` type and its `payload.ref_type` is `branch` . So someone named \"treydock\" (`actor.login`) created a repository branch called \"development\" (`payload.ref`) in the first second of March 1, 2015 (`created_at`) .\n",
        "\n",
        "1. Load the textfile into an RDD (note: spark can read gzipped files directly!). Convert this RDD (which consists of string elements) to an RDD where each element is a JSON object (hint: use the `json.loads` function from the `json` module to convert a string into a JSON object).\n",
        "\n",
        "2. Filter this RDD of JSON objects to retain only those objects that represent push activities (where `type` equals `PushEvent`)\n",
        "\n",
        "3. Count the number of push events.\n",
        "\n",
        "4. Compute the number of push events, grouped per `actor.login`. \n",
        "\n",
        "5. Retrieve the results of (4) in sorted order, where logins with higher number of pushes come first. Retrieve the 10 first such results (which contain the highest number of pushes)\n",
        "\n",
        "6. You are representing a company and need to retrieving the number of pushes for every employee in the company. The file `data/github/employees.txt` contains a list of all employee login names at your company.\n",
        "\n",
        "Extra: if you want to experiment with larger datasets, download more log data from the github archive website and re-do the exercises above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7zHWWp7aw8G"
      },
      "source": [
        "<font color='violet'>1. Load the textfile into an RDD (note: spark can read gzipped files directly!). Convert this RDD (which consists of string elements) to an RDD where each element is a JSON object (hint: use the json.loads function from the json module to convert a string into a JSON object):</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_m0bj1Yympe",
        "outputId": "85be55a0-e0a1-4186-f839-5e6073f0c0d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '2614896652',\n",
              "  'type': 'CreateEvent',\n",
              "  'actor': {'id': 739622,\n",
              "   'login': 'treydock',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/users/treydock',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/739622?'},\n",
              "  'repo': {'id': 23934080,\n",
              "   'name': 'Early-Modern-OCR/emop-dashboard',\n",
              "   'url': 'https://api.github.com/repos/Early-Modern-OCR/emop-dashboard'},\n",
              "  'payload': {'ref': 'development',\n",
              "   'ref_type': 'branch',\n",
              "   'master_branch': 'master',\n",
              "   'description': '',\n",
              "   'pusher_type': 'user'},\n",
              "  'public': True,\n",
              "  'created_at': '2015-03-01T00:00:00Z',\n",
              "  'org': {'id': 10965476,\n",
              "   'login': 'Early-Modern-OCR',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/orgs/Early-Modern-OCR',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/10965476?'}},\n",
              " {'id': '2614896653',\n",
              "  'type': 'PushEvent',\n",
              "  'actor': {'id': 9063348,\n",
              "   'login': 'bezerrathm',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/users/bezerrathm',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/9063348?'},\n",
              "  'repo': {'id': 31481156,\n",
              "   'name': 'bezerrathm/HuffmanCoding',\n",
              "   'url': 'https://api.github.com/repos/bezerrathm/HuffmanCoding'},\n",
              "  'payload': {'push_id': 588068425,\n",
              "   'size': 1,\n",
              "   'distinct_size': 1,\n",
              "   'ref': 'refs/heads/master',\n",
              "   'head': '570ad890d78525dfc10364901c41b8236e2c783a',\n",
              "   'before': '6dda286a3a1c254184f1456b5fefc139ff9dce66',\n",
              "   'commits': [{'sha': '570ad890d78525dfc10364901c41b8236e2c783a',\n",
              "     'author': {'email': 'ba1618c3d509021c3c759fa9aad031c4a38fe046@gmail.com',\n",
              "      'name': 'Thiago Henrique Menêses Bezerra'},\n",
              "     'message': 'Create other.h',\n",
              "     'distinct': True,\n",
              "     'url': 'https://api.github.com/repos/bezerrathm/HuffmanCoding/commits/570ad890d78525dfc10364901c41b8236e2c783a'}]},\n",
              "  'public': True,\n",
              "  'created_at': '2015-03-01T00:00:00Z'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "githubRDD = sc.textFile('data/github/2015-03-01-0.json.gz')\n",
        "import json\n",
        "githubRDD = githubRDD.map(lambda x:json.loads(x))\n",
        "githubRDD.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVZ3L17Ra2b5"
      },
      "source": [
        "<font color='violet'> 2. Filter this dataframe to retain only those rows that represent push activities (where type equals PushEvent).\n",
        "\n",
        "Again, sorting is not strictly needed:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY3iQeqLDN2n",
        "outputId": "1bad9da2-7e8c-4ddb-c6c5-8ef466f62382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '2614921736',\n",
              "  'type': 'PushEvent',\n",
              "  'actor': {'id': 4584144,\n",
              "   'login': '0000marcell',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/users/0000marcell',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/4584144?'},\n",
              "  'repo': {'id': 31145226,\n",
              "   'name': '0000marcell/BLANK_SITE',\n",
              "   'url': 'https://api.github.com/repos/0000marcell/BLANK_SITE'},\n",
              "  'payload': {'push_id': 588078540,\n",
              "   'size': 1,\n",
              "   'distinct_size': 1,\n",
              "   'ref': 'refs/heads/master',\n",
              "   'head': '1bc3f18a8ccc5bd51f4568533af3530a14511252',\n",
              "   'before': '8a3b9fbbb7445ae809a6441414d6989112fd20e6',\n",
              "   'commits': [{'sha': '1bc3f18a8ccc5bd51f4568533af3530a14511252',\n",
              "     'author': {'email': '3b41845c55bd0cbc15aa56425f563af645db6204@gmail.com',\n",
              "      'name': 'Marcell Monteiro Cruz'},\n",
              "     'message': 'coffee-script implemented',\n",
              "     'distinct': True,\n",
              "     'url': 'https://api.github.com/repos/0000marcell/BLANK_SITE/commits/1bc3f18a8ccc5bd51f4568533af3530a14511252'}]},\n",
              "  'public': True,\n",
              "  'created_at': '2015-03-01T00:31:51Z'},\n",
              " {'id': '2614920641',\n",
              "  'type': 'PushEvent',\n",
              "  'actor': {'id': 7462135,\n",
              "   'login': '01000101',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/users/01000101',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/7462135?'},\n",
              "  'repo': {'id': 28792932,\n",
              "   'name': 'joshtipton28/elocator',\n",
              "   'url': 'https://api.github.com/repos/joshtipton28/elocator'},\n",
              "  'payload': {'push_id': 588078053,\n",
              "   'size': 1,\n",
              "   'distinct_size': 1,\n",
              "   'ref': 'refs/heads/master',\n",
              "   'head': '5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d',\n",
              "   'before': '2e6410476d923554680abbd17db6e1d8bed28b1c',\n",
              "   'commits': [{'sha': '5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d',\n",
              "     'author': {'email': '27bc267138cd2af758dc9d89b4908c73da379352@gmail.com',\n",
              "      'name': 'Joshua Cornutt'},\n",
              "     'message': 'Changed presentation of clicks left for groups',\n",
              "     'distinct': True,\n",
              "     'url': 'https://api.github.com/repos/joshtipton28/elocator/commits/5cb2c5f4d1987c53a8ce4c451fbc77274c8fc53d'}]},\n",
              "  'public': True,\n",
              "  'created_at': '2015-03-01T00:30:19Z'},\n",
              " {'id': '2614902080',\n",
              "  'type': 'PushEvent',\n",
              "  'actor': {'id': 5255678,\n",
              "   'login': '05K4R1N',\n",
              "   'gravatar_id': '',\n",
              "   'url': 'https://api.github.com/users/05K4R1N',\n",
              "   'avatar_url': 'https://avatars.githubusercontent.com/u/5255678?'},\n",
              "  'repo': {'id': 30512343,\n",
              "   'name': '05K4R1N/Hospital',\n",
              "   'url': 'https://api.github.com/repos/05K4R1N/Hospital'},\n",
              "  'payload': {'push_id': 588070349,\n",
              "   'size': 1,\n",
              "   'distinct_size': 1,\n",
              "   'ref': 'refs/heads/registrando_pacientes',\n",
              "   'head': 'b54127ecb5542d9d668e0d7d45ab244cc9240101',\n",
              "   'before': '47a0ed9e4517e184daa60af603812a4a93a69bb5',\n",
              "   'commits': [{'sha': 'b54127ecb5542d9d668e0d7d45ab244cc9240101',\n",
              "     'author': {'email': 'ab83d1206a9cc03d66b45fd9a688047d192b7ffb@hotmail.com',\n",
              "      'name': '05K4R1N'},\n",
              "     'message': 'Cambiando interfaz...',\n",
              "     'distinct': True,\n",
              "     'url': 'https://api.github.com/repos/05K4R1N/Hospital/commits/b54127ecb5542d9d668e0d7d45ab244cc9240101'}]},\n",
              "  'public': True,\n",
              "  'created_at': '2015-03-01T00:05:15Z'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pushRDD = githubRDD.filter(lambda x:x['type']=='PushEvent').sortBy(lambda x:x[\"actor\"][\"login\"])\n",
        "pushRDD.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7et0o6yocW7I"
      },
      "source": [
        "<font color='violet'>3. Count the number of push events:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwvIKgMCwty",
        "outputId": "4acd58ba-3c76-4032-bf52-2ce32d883ee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8793"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "pushRDD.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlceONrUEx6B"
      },
      "source": [
        "\n",
        "<font color='violet'> 4. Compute the number of push events, grouped per `actor.login`.\n",
        "\n",
        "Again, sorting is not strictly needed:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofr2jxZEE9hi",
        "outputId": "f61207a7-1005-44f1-bfc7-aec05b005e7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0000marcell', 1), ('01000101', 1), ('05K4R1N', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "pushbyloginRDD = pushRDD.groupBy(lambda x: x['actor']['login']).map(lambda x: (x[0], len(x[1]))).sortByKey()\n",
        "pushbyloginRDD.take(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5BXyJpwdRrT"
      },
      "source": [
        "<font color='violet'>5. Retrieve the results of (4) in sorted order, where logins with higher number of pushes come first. Retrieve the 10 first such results (which contain the highest number of pushes):</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcxqSIY0C67n",
        "outputId": "6a8b5be0-0e2f-42a9-fa5a-41895a1cd57b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('greatfirebot', 192),\n",
              " ('diversify-exp-user', 146),\n",
              " ('KenanSulayman', 72),\n",
              " ('manuelrp07', 45),\n",
              " ('mirror-updates', 42),\n",
              " ('tryton-mirror', 37),\n",
              " ('Somasis', 26),\n",
              " ('direwolf-github', 24),\n",
              " ('EmanueleMinotto', 22),\n",
              " ('hansliu', 21)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pushbyloginRDD.sortBy(lambda x:x[1],False).take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec56_973dujZ"
      },
      "source": [
        "<font color='violet'> 6. You are representing a company and need to retrieve the number of pushes for every employee in the company. The file `data/github/employees.txt` contains a list of all employee login names at your company.\n",
        "\n",
        "IMPORTANT: All the employees in the file data/github/employees.txt seem to have at least one push. I have added additional employees with zero pushes to make sure my code is robust:\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzsG0xLl6W5D",
        "outputId": "7cf576ad-4039-4dea-ebcf-cde8dcc7b3ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AiMadobe',\n",
              " 'Akkyie',\n",
              " 'An employee with zero pushes',\n",
              " 'Another employee with zero pushes',\n",
              " 'BatMiles']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "employeesRDD = sc.textFile('data/github/employees.txt')\n",
        "employeesRDD = employeesRDD.union(sc.parallelize(['An employee with zero pushes','Another employee with zero pushes']))\n",
        "employeesRDD.sortBy(lambda x: x[0]).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tGhz3NaChaw"
      },
      "source": [
        "<font color='violet'>The left outer join method is applied to employeesRDD is used to make sure all employees, even those who do not push, are present in the join. Those who do not push have value `None`, which must be replaced by `0`. Sorting is done for convenience, but is not strictly necessary.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh5yrDAg_kC9",
        "outputId": "cb295fd1-27fa-43cd-f9b9-c49a5a6c4f87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Another employee with zero pushes', 0),\n",
              " ('An employee with zero pushes', 0),\n",
              " ('barnardn', 1),\n",
              " ('Ramzawulf', 1),\n",
              " ('summersd', 1),\n",
              " ('eckardjf', 1),\n",
              " ('elhaddad1', 1),\n",
              " ('mikebronner', 1),\n",
              " ('serranoarevalo', 1),\n",
              " ('alexanderdidenko', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pushersRDD = employeesRDD.groupBy(lambda x: x).leftOuterJoin(pushbyloginRDD).mapValues(lambda x: x[1] if x[1] != None else 0).sortBy(lambda x: x[1])\n",
        "pushersRDD.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxjfVtdnBMTU",
        "outputId": "93000196-b3c9-45df-e28f-ae5c6e8bf231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('KenanSulayman', 72), ('manuelrp07', 45), ('Somasis', 26)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "pushersRDD.sortBy(lambda x: x[1], ascending = False).take(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8fcq1LyBwEl"
      },
      "source": [
        "<font color='violet'>Stopping Spark:</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n5P2l2yHIDbp"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}